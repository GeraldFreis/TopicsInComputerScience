{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "import os\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "tf.config.set_visible_devices([], 'GPU') # turning GPU use off as tensors exceed 10000*1000*50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing the data and CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"../IMDB_with_predictions.csv\")\n",
    "reviews = raw_df.review\n",
    "sentiment = raw_df.CNN_Predictions\n",
    "\n",
    "CNN = keras.models.load_model(\"../CNN_Non_Dense\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the inputs so that we can vectorise them in the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  27    4    1 ...    0    0    0]\n",
      " [   3  393  120 ...    0    0    0]\n",
      " [  10  190   11 ...    0    0    0]\n",
      " ...\n",
      " [  10  235    3 ...    0    0    0]\n",
      " [ 145  166    5 ...    0    0    0]\n",
      " [  54   27 5892 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=37500)\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "tokenized_reviews = tokenizer.texts_to_sequences(reviews)\n",
    "padded_reviews = tf.keras.utils.pad_sequences(tokenized_reviews, padding=\"post\", maxlen=1000)\n",
    "print(padded_reviews)\n",
    "flatten_layer = keras.layers.Flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1000, 50)          1875000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 998, 32)           4832      \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 32)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                330       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,880,173\n",
      "Trainable params: 1,880,173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(CNN.summary())\n",
    "# setting up our model that takes output of embedding layer and predicts output\n",
    "Embedding_layer = keras.Model(inputs=CNN.inputs, outputs=CNN.get_layer(name=\"embedding\").output)\n",
    "embedding_raw = Embedding_layer(padded_reviews[0:50000:1])\n",
    "embedding_final = np.array(flatten_layer(embedding_raw))\n",
    "train_embedding_x, test_embedding_x, train_embedding_y, test_embedding_y = train_test_split(embedding_final, sentiment, random_state=1000, shuffle=True, test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the embedding tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer\n",
      "Training accuracy: 1.0 vs Testing Accuracy 0.5574666666666667\n"
     ]
    }
   ],
   "source": [
    "embedding_tree = RandomForestClassifier(criterion=\"entropy\").fit(train_embedding_x, train_embedding_y)\n",
    "training_embedding_prediction = embedding_tree.predict(train_embedding_x)\n",
    "test_embedding_prediction = embedding_tree.predict(test_embedding_x)\n",
    "training_embedding_prediction_accuracy = sk.metrics.accuracy_score(train_embedding_y, training_embedding_prediction, normalize=True)\n",
    "test_embedding_prediction_accuracy = sk.metrics.accuracy_score(test_embedding_y, test_embedding_prediction, normalize=True)\n",
    "print(\"Embedding layer\\nTraining accuracy: {} vs Testing Accuracy {}\".format(training_embedding_prediction_accuracy, test_embedding_prediction_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building convolutional model and getting output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building model \n",
    "convolutional_model = keras.Sequential()\n",
    "convolutional_model.add(CNN.get_layer(name=\"embedding\"))\n",
    "convolutional_model.add(CNN.get_layer(name=\"conv1d\"))\n",
    "\n",
    "# getting output given the padded input\n",
    "convolutional_raw = convolutional_model(padded_reviews)\n",
    "convolutional_final = np.array(flatten_layer(convolutional_raw))\n",
    "train_conv_x, test_conv_x, train_conv_y, test_conv_y = train_test_split(convolutional_final, sentiment, random_state=1000, shuffle=True, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the convolutional tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution layer\n",
      "Training accuracy: 1.0 vs Testing Accuracy 0.5474666666666667\n"
     ]
    }
   ],
   "source": [
    "conv_tree = RandomForestClassifier(criterion=\"entropy\").fit(train_conv_x, train_conv_y)\n",
    "training_conv_prediction = conv_tree.predict(train_conv_x)\n",
    "test_conv_prediction = conv_tree.predict(test_conv_x)\n",
    "training_conv_prediction_accuracy = sk.metrics.accuracy_score(train_conv_y, training_conv_prediction, normalize=True)\n",
    "test_conv_prediction_accuracy = sk.metrics.accuracy_score(test_conv_y, test_conv_prediction, normalize=True)\n",
    "print(\"Convolution layer\\nTraining accuracy: {} vs Testing Accuracy {}\".format(training_conv_prediction_accuracy, test_conv_prediction_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the pooling tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_model = keras.Sequential()\n",
    "pooling_model.add(CNN.get_layer(name=\"embedding\"))\n",
    "pooling_model.add(CNN.get_layer(name=\"conv1d\"))\n",
    "pooling_model.add(CNN.get_layer(name=\"global_max_pooling1d\"))\n",
    "\n",
    "# getting outputs from model\n",
    "\n",
    "pooling_raw = pooling_model(padded_reviews)\n",
    "pooling_final = np.array(flatten_layer(pooling_raw))\n",
    "train_pooling_x, test_pooling_x, train_pooling_y, test_pooling_y = train_test_split(pooling_final, sentiment, random_state=1000, shuffle=True, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and running the pooling DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooling layer\n",
      "Training accuracy: 1.0 vs Testing Accuracy 0.6106666666666667\n"
     ]
    }
   ],
   "source": [
    "pooling_tree = RandomForestClassifier(criterion=\"entropy\").fit(train_pooling_x, train_pooling_y)\n",
    "training_pooling_prediction = pooling_tree.predict(train_pooling_x)\n",
    "test_pooling_prediction = pooling_tree.predict(test_pooling_x)\n",
    "training_pooling_prediction_accuracy = sk.metrics.accuracy_score(train_pooling_y, training_pooling_prediction, normalize=True)\n",
    "test_pooling_prediction_accuracy = sk.metrics.accuracy_score(test_pooling_y, test_pooling_prediction, normalize=True)\n",
    "print(\"Pooling layer\\nTraining accuracy: {} vs Testing Accuracy {}\".format(training_pooling_prediction_accuracy, test_pooling_prediction_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building first dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model = keras.Sequential()\n",
    "dense_model.add(CNN.get_layer(name=\"embedding\"))\n",
    "dense_model.add(CNN.get_layer(name=\"conv1d\"))\n",
    "dense_model.add(CNN.get_layer(name=\"global_max_pooling1d\"))\n",
    "dense_model.add(CNN.get_layer(name=\"dense\"))\n",
    "# getting outputs from model\n",
    "\n",
    "dense_raw = dense_model(padded_reviews)\n",
    "dense_final = np.array(flatten_layer(dense_raw))\n",
    "train_dense_x, test_dense_x, train_dense_y, test_dense_y = train_test_split(dense_final, sentiment, random_state=1000, shuffle=True, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building dense tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense layer\n",
      "Training accuracy: 1.0 vs Testing Accuracy 0.5748666666666666\n"
     ]
    }
   ],
   "source": [
    "dense_tree = RandomForestClassifier(criterion=\"entropy\").fit(train_dense_x, train_dense_y)\n",
    "training_dense_prediction = dense_tree.predict(train_dense_x)\n",
    "test_dense_prediction = dense_tree.predict(test_dense_x)\n",
    "training_dense_prediction_accuracy = sk.metrics.accuracy_score(train_dense_y, training_dense_prediction, normalize=True)\n",
    "test_dense_prediction_accuracy = sk.metrics.accuracy_score(test_dense_y, test_dense_prediction, normalize=True)\n",
    "print(\"Dense layer\\nTraining accuracy: {} vs Testing Accuracy {}\".format(training_dense_prediction_accuracy, test_dense_prediction_accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
