{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code allows the visualisation of SHAP values for interpretability measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data_Analysis_on_sentences/IMDB_sentences.csv\")[0:1000:1]\n",
    "model = keras.models.load_model(\"../CNN_Non_Dense\")\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.Sentences)\n",
    "tokenized_texts = tokenizer.texts_to_sequences(df.Sentences)\n",
    "padded_texts = pad_sequences(tokenized_texts, padding=\"post\", maxlen=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the SHAP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22/149 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 23:50:50.969373: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 1s 5ms/step\n",
      "149/149 [==============================] - 1s 7ms/step\n",
      "149/149 [==============================] - 1s 7ms/step\n",
      "149/149 [==============================] - 1s 7ms/step\n",
      "149/149 [==============================] - 1s 7ms/step\n",
      "149/149 [==============================] - 1s 7ms/step\n",
      "149/149 [==============================] - 1s 7ms/step\n",
      "149/149 [==============================] - 1s 7ms/step\n",
      "149/149 [==============================] - 1s 7ms/step\n",
      "149/149 [==============================] - 1s 6ms/step\n",
      "149/149 [==============================] - 1s 7ms/step\n",
      "149/149 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer:  50%|█████     | 1/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 1s 7ms/step\n",
      "134/134 [==============================] - 1s 7ms/step\n",
      "134/134 [==============================] - 1s 7ms/step\n",
      "134/134 [==============================] - 1s 6ms/step\n",
      "134/134 [==============================] - 1s 7ms/step\n",
      "134/134 [==============================] - 1s 7ms/step\n",
      "134/134 [==============================] - 1s 7ms/step\n",
      "134/134 [==============================] - 1s 7ms/step\n",
      "134/134 [==============================] - 1s 7ms/step\n",
      "134/134 [==============================] - 1s 7ms/step\n",
      "134/134 [==============================] - 1s 7ms/step\n",
      "134/134 [==============================] - 1s 7ms/step\n",
      "115/115 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 3it [00:27, 13.73s/it]               \n"
     ]
    }
   ],
   "source": [
    "explainer = shap.Explainer(model.predict, padded_texts[0:250:1], max_evals=2001)\n",
    "explainer.max_evals = 10000\n",
    "# print(padded_texts[0])\n",
    "first_explanation = explainer(padded_texts[0:2:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an object to store explanations vs shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Word': 'has', 'SHAP': 0.07355170280566185}, {'Word': 'episode', 'SHAP': 0.04669677018243714}, {'Word': 'the', 'SHAP': 0.024299972482939986}, {'Word': 'mentioned', 'SHAP': 0.018427379910522172}, {'Word': 'reviewers', 'SHAP': 0.0071822783882631485}, {'Word': '1', 'SHAP': 0.004611469485578993}, {'Word': 'be', 'SHAP': -0.001872659689997865}, {'Word': 'One', 'SHAP': -0.012602398639193003}, {'Word': 'that', 'SHAP': -0.015150573688211185}, {'Word': 'just', 'SHAP': -0.021365733130425113}, {'Word': 'Oz', 'SHAP': -0.02817006213590569}, {'Word': 'of', 'SHAP': -0.03450816942661048}, {'Word': 'hooked', 'SHAP': -0.08781781074401579}, {'Word': 'other', 'SHAP': -0.09439156273008607}, {'Word': 'after', 'SHAP': -0.10192505101922676}, {'Word': 'watching', 'SHAP': -0.10442404497560942}, {'Word': \"you'll\", 'SHAP': -0.19786665668106215}]\n"
     ]
    }
   ],
   "source": [
    "first_shaps = first_explanation[0].values\n",
    "word_list = list(df.iloc[0].Sentences.split(sep=\" \"))\n",
    "word_vs_shap = list() # list containing the respective word and its shapley additive explanation value\n",
    "\n",
    "for i in range(len(word_list)):\n",
    "    word_vs_shap.append({\"Word\": word_list[i], \"SHAP\": first_shaps[i]})\n",
    "\n",
    "# sorting it so we can visualise it easily\n",
    "\n",
    "def bubbleSort(arr):\n",
    "    n = len(arr)\n",
    "    # optimize code, so if the array is already sorted, it doesn't need\n",
    "    # to go through the entire process\n",
    "    swapped = False\n",
    "    # Traverse through all array elements\n",
    "    for i in range(n-1):\n",
    "        # range(n) also work but outer loop will\n",
    "        # repeat one time more than needed.\n",
    "        # Last i elements are already in place\n",
    "        for j in range(0, n-i-1):\n",
    " \n",
    "            # traverse the array from 0 to n-i-1\n",
    "            # Swap if the element found is greater\n",
    "            # than the next element\n",
    "            if arr[j][\"SHAP\"] < arr[j + 1][\"SHAP\"]:\n",
    "                swapped = True\n",
    "                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n",
    "         \n",
    "        if not swapped:\n",
    "            # if we haven't needed to make a single swap, we \n",
    "            # can just exit the main loop.\n",
    "            return\n",
    "sorted_word_vs_shap = bubbleSort(word_vs_shap)\n",
    "print(word_vs_shap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising the SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0 position: 32 layer: 1\n",
      "i: 1 position: 16 layer: 3\n",
      "i: 2 position: 48 layer: 3\n",
      "i: 3 position: 8 layer: 5\n",
      "i: 4 position: 16 layer: 5\n",
      "i: 5 position: 48 layer: 5\n",
      "i: 6 position: 56 layer: 5\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "max_size=64\n",
    "\n",
    "root = tk.Tk()\n",
    "frm = ttk.Frame(root, padding=10)\n",
    "frm.grid()\n",
    "frm.rowconfigure(max_size*3) \n",
    "frm.columnconfigure(max_size)\n",
    "sorted_word_vs_shap = word_vs_shap\n",
    "layer = 1; position = 0\n",
    "counter = 0\n",
    "l = [32,16,48,8,24,40,54]\n",
    "for i in range(0, 7):\n",
    "    if(i != 0):\n",
    "        if (counter == 1):\n",
    "            position += int(max_size / pow(2, layer-4))\n",
    "            counter = 0\n",
    "        else:\n",
    "            position += int(max_size / pow(2, layer-2))\n",
    "            counter += 1        \n",
    "    else:\n",
    "        position += 32\n",
    "    \n",
    "    if(i > pow(2, layer-2)):\n",
    "        if(counter == 0):\n",
    "            position = int(max_size / pow(2, layer))\n",
    "        else:\n",
    "            position = int(max_size / pow(2, layer+1))\n",
    "        layer += 2\n",
    "        counter = 0\n",
    "    \n",
    "\n",
    "    print(\"i: {} position: {} layer: {}\".format(i, position, layer))\n",
    "    # the starting position is max_size / pow(2, layer)\n",
    "    ttk.Label(root, text=round(sorted_word_vs_shap[i][\"SHAP\"], 5), width=30, wraplength=100, justify=\"center\", font=(\"Arial\", 14)).grid(column=l[i], row=layer)\n",
    "    ttk.Label(root, text=sorted_word_vs_shap[i][\"Word\"], width=30, wraplength=100, justify=\"center\", font=(\"Arial\", 14)).grid(column=l[i], row=layer+1)\n",
    "\n",
    "\n",
    "# root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphsageoncora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
