{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_data = pd.read_csv(\"IMDB_dataset_final.csv\", low_memory=False)\n",
    "\n",
    "# printing statements to check the variables\n",
    "raw_x = raw_data.review; # print(raw_x)\n",
    "raw_y = raw_data.sentiment; # print(raw_y)\n",
    "\n",
    "number_of_words_in_dic = 37500; \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=number_of_words_in_dic) # to tokenize the words for learning\n",
    "tokenizer.fit_on_texts(raw_x)\n",
    "tokenized_sentiments = tokenizer.texts_to_sequences(raw_x) # converting the words to number arrays\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "padded_tokenized_sentiments= tf.keras.utils.pad_sequences(tokenized_sentiments, padding=\"post\", maxlen=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential # we will be using this for the CNN\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code beneath changes every time you run it and hence shows a bad approach to extracting the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1000, 50)          1875000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 998, 32)           4832      \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 32)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                330       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,880,173\n",
      "Trainable params: 1,880,173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# importing the trained keras cnn\n",
    "CNN = tf.keras.models.load_model(\"Trained_CNN_for_sentiment_prediction\")\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the node embedding outputs from the STABLE CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.12047946 -0.07198443 -0.03228364 ...  0.00455372 -0.14110881\n",
      "   -0.00318262]\n",
      "  [ 0.02522953 -0.14398038 -0.13661358 ... -0.04930472  0.06729973\n",
      "   -0.17320693]\n",
      "  [-0.04343206 -0.04485501  0.12286492 ... -0.04977522 -0.06138654\n",
      "   -0.02183243]\n",
      "  ...\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]]\n",
      "\n",
      " [[-0.06885604 -0.09118391 -0.07906064 ... -0.02250706 -0.14835048\n",
      "   -0.02511178]\n",
      "  [-0.08446779 -0.0147468  -0.03923324 ...  0.03985319  0.07039006\n",
      "   -0.01437815]\n",
      "  [ 0.09084012  0.02692487  0.08453914 ...  0.00336978 -0.03451585\n",
      "   -0.16510229]\n",
      "  ...\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]]\n",
      "\n",
      " [[-0.00155568 -0.0764398  -0.14510995 ...  0.05492318 -0.00460473\n",
      "    0.06972919]\n",
      "  [-0.0402974  -0.04470833 -0.07801381 ...  0.09282771  0.07706526\n",
      "   -0.06520386]\n",
      "  [-0.06765638  0.01631243 -0.19508056 ...  0.08385246 -0.00294033\n",
      "    0.01059346]\n",
      "  ...\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.00155568 -0.0764398  -0.14510995 ...  0.05492318 -0.00460473\n",
      "    0.06972919]\n",
      "  [ 0.12775144  0.08262446  0.12118261 ... -0.10830903  0.07931929\n",
      "    0.1273143 ]\n",
      "  [-0.06885604 -0.09118391 -0.07906064 ... -0.02250706 -0.14835048\n",
      "   -0.02511178]\n",
      "  ...\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]]\n",
      "\n",
      " [[-0.07329494  0.00613164  0.1322469  ...  0.18629013  0.02151854\n",
      "    0.09569946]\n",
      "  [ 0.01130149 -0.05174365  0.00300512 ... -0.02490812 -0.07301007\n",
      "    0.08033442]\n",
      "  [ 0.06853318 -0.00207043  0.02429241 ...  0.06122869  0.03410452\n",
      "   -0.08830179]\n",
      "  ...\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]]\n",
      "\n",
      " [[ 0.07681394  0.11568742  0.22320893 ... -0.15117237 -0.09676971\n",
      "    0.11119228]\n",
      "  [-0.12047946 -0.07198443 -0.03228364 ...  0.00455372 -0.14110881\n",
      "   -0.00318262]\n",
      "  [ 0.01763552 -0.0583682   0.01814335 ... -0.07587489  0.06286362\n",
      "    0.03684347]\n",
      "  ...\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]\n",
      "  [ 0.01882174  0.00709695 -0.01237831 ... -0.06010544 -0.07130452\n",
      "   -0.12374803]]], shape=(50000, 1000, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# getting the outputs from the embedding layer of the CNN\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "embeddings = keras.Model(inputs=CNN.inputs, outputs=CNN.get_layer(name=\"embedding\").output) \n",
    "embedding_outputs = embeddings(padded_tokenized_sentiments[0:50000:1])\n",
    "\n",
    "print(embedding_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the outputs to the pandas dataframe and then a new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "variabl = tf.Variable(embedding_outputs)\n",
    "# tf.saved_model.save(variabl,\"Embeddings_outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50000, 1000, 50])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variabl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting this big tensor up into train test and validation segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([37314, 20848, 16191, ...,  6215,  4695, 42419])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m model_selection\n\u001b[1;32m----> 2\u001b[0m train_x, test_x \u001b[39m=\u001b[39m model_selection\u001b[39m.\u001b[39;49mtrain_test_split(variabl, random_state\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.3\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\baseEnv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\baseEnv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2640\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2636\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m   2638\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[1;32m-> 2640\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\n\u001b[0;32m   2641\u001b[0m     chain\u001b[39m.\u001b[39;49mfrom_iterable(\n\u001b[0;32m   2642\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m arrays\n\u001b[0;32m   2643\u001b[0m     )\n\u001b[0;32m   2644\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\baseEnv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2642\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2636\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m   2638\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[0;32m   2640\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2641\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> 2642\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m   2643\u001b[0m     )\n\u001b[0;32m   2644\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\baseEnv\\lib\\site-packages\\sklearn\\utils\\__init__.py:355\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m    354\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m    356\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    357\u001b[0m     \u001b[39mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\baseEnv\\lib\\site-packages\\sklearn\\utils\\__init__.py:184\u001b[0m, in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    183\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m--> 184\u001b[0m \u001b[39mreturn\u001b[39;00m array[key] \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m array[:, key]\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\baseEnv\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1350\u001b[0m, in \u001b[0;36m_SliceHelperVar\u001b[1;34m(var, slice_spec)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_SliceHelperVar\u001b[39m(var, slice_spec):\n\u001b[0;32m   1308\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a slice helper object given a variable.\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \n\u001b[0;32m   1310\u001b[0m \u001b[39m  This allows creating a sub-tensor from part of the current contents\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \n\u001b[0;32m   1348\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1350\u001b[0m   \u001b[39mreturn\u001b[39;00m _slice_helper(var\u001b[39m.\u001b[39;49mvalue(), slice_spec, var)\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\baseEnv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\freis\\anaconda3\\envs\\baseEnv\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:906\u001b[0m, in \u001b[0;36m_check_index\u001b[1;34m(idx)\u001b[0m\n\u001b[0;32m    901\u001b[0m dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(idx, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    902\u001b[0m \u001b[39mif\u001b[39;00m (dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m dtypes\u001b[39m.\u001b[39mas_dtype(dtype) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _SUPPORTED_SLICE_DTYPES \u001b[39mor\u001b[39;00m\n\u001b[0;32m    903\u001b[0m     idx\u001b[39m.\u001b[39mshape \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(idx\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m    904\u001b[0m   \u001b[39m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[39;00m\n\u001b[0;32m    905\u001b[0m   \u001b[39m# will break `_slice_helper` contract.\u001b[39;00m\n\u001b[1;32m--> 906\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(_SLICE_TYPE_ERROR \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, got \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(idx))\n",
      "\u001b[1;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([37314, 20848, 16191, ...,  6215,  4695, 42419])"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "train_x, test_x = model_selection.train_test_split(variabl, random_state=1000, test_size=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
